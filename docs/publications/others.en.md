---
layout: default
---
# Non Reviewed (English) 

- **Japan-Taiwan Data AI Module Platform for Analyzing Remote Sensing data, Part 2.**  <span onmouseover="document.getElementById('pragma36jeju').style.display = 'block'"  onmouseout="document.getElementById('pragma36jeju').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, et. al
, *PRAGMA 36*    , 2019 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="pragma36jeju"> Sharing data and AI module is the key to accelerate the use of AI. This demo is to demonstrate the data and AI module platform which is built between AIST and NCHC. AI module for detecting solar panels by analyzing remote sensing data was developed by AIST. We will demonstrate that the AI module is built as a docker image can be easily deployed at NCHC for analyzing Formosat-2 data</div> </blockquote>



- **Japan-Taiwan Data AI Module Platform for Analyzing Remote Sensing data, Part 3.**  <span onmouseover="document.getElementById('pragma37sandiego').style.display = 'block'"  onmouseout="document.getElementById('pragma37sandiego').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, et. al
, *PRAGMA 37*    , 2019 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="pragma37sandiego"> Sharing data and AI module is the key to accelerate the use of AI. This demo is to demonstrate the data and AI module platform which is built between AIST and NCHC. AI module for detecting solar panels by analyzing remote sensing data was developed by AIST. We will demonstrate that the AI module is built as a docker image can be easily deployed at NCHC for analyzing Formosat-2 data</div> </blockquote>



- **A Study of a Scalable Distributed Stream Processing Infrastructure Using Ray and Apache Kafka**  <span onmouseover="document.getElementById('bigdataposter2018-kato').style.display = 'block'"  onmouseout="document.getElementById('bigdataposter2018-kato').style.display = 'none'">[abst]</span>   
Kasumi Kato, Atsuko Takefusa, Hidemoto Nakada, Masato Oguchi
, *IEEE Bigdata 2018(poster)*    , 2018 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="bigdataposter2018-kato"> The spread of various sensors and the development of cloud computing technologies enable the accumulation and use of many live logs in ordinary homes. To operate a service that utilizes sensor data, those data are transmitted from sensors in ordinary homes to a cloud and analyzed in the cloud. However, services that involve moving image analysis require large amounts of data to be transferred continuously and high computing power for the analysis; hence, it is difficult to process them in real time in the cloud using a conventional stream data processing framework. We study a construction scheme for a highly efficient distributed stream processing infrastructure that enables scalable processing in moving image recognition according to the amount of data that is transmitted from sensors.</div> </blockquote>



- **Japan-Taiwan Data and AI module platform for analyzing remote sensing data**  <span onmouseover="document.getElementById('pragma35demo').style.display = 'block'"  onmouseout="document.getElementById('pragma35demo').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, et.al
, *Pacific Rim Application and Grid Middleware Assembly (Pragma) 35*    , 2018 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="pragma35demo"> Sharing data and AI module is the key to accelerate the use of AI. This demo is to demonstrate the data and AI module platform which is built  between AIST and NCHC. AI module for detecting solar panels by analyzing remote sensing data was developed by AIST. We will demonstrate that the AI module which is built as a docker image can be easily deployed at NCHC for analyzing Formosat-2 data in Taiwan.</div> </blockquote>



- **Sub-policy pruning in Meta Learning Shared Hierarchies**  <span onmouseover="document.getElementById('pragma-hon').style.display = 'block'"  onmouseout="document.getElementById('pragma-hon').style.display = 'none'">[abst]</span>   
Ging Hong, Yusuke Tanimura, Hidemoto Nakada
, *34th meeting of the Pacific Rim Applications and Grid Middleware Assembly (PRAGMA 34).*    , 2018 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="pragma-hon"> MLSH (Meta Learning Shared Hierarchies) is a meta learning method that divide a policy into multiple sub-policies and a master-policy that picks one of the sub-policies to be actually used. By training sub-policies in advance, master policy can rapidly adjust to given environments. However, MLSH is not suitable for complicated environments. In complicated environments, a number of sub-policies are required,  and it is very difficult to train them properly. We propose a method to effectively prune excessive sub-policies to give better chance the other sub-policies to be trained.</div> </blockquote>



- **Toward image inbetweening using Latent Model**  <span onmouseover="document.getElementById('pragma-paulino').style.display = 'block'"  onmouseout="document.getElementById('pragma-paulino').style.display = 'none'">[abst]</span>   
Paulino Cristovao, Yusuke Tanimura, Hidemoto Nakada, Hideki Asoh
, *34th meeting of the Pacific Rim Applications and Grid Middleware Assembly (PRAGMA 34).*    , 2018 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="pragma-paulino"> Image interpolation is a well known problem in computer vision. Many approaches are restricted to optical flow and convolutional neural network. In this work, we present an alternative approach based on generative models to generate in between images (interpolation) using variational autoencoders (VAE). The goals are: Generate in between images using hidden structures (latent variables), and yield latent features that generalize well. Our architecture composed of three networks (VAE) that share weights. We train the network feeding three continous frames so that the second latent variables become close to the average of the first and third latent variables. To get interporated image from two images, we can just reconstract the image from the avarage of the two images&#x27; latent variables. We evaluate the result by comparing the ground truth image and the generated one to evaluate the in between image. In addition we show the reconstructed images using the same network.</div> </blockquote>



- **Consideration of Parallel Data Processing over an Apache Spark Cluster**  <span onmouseover="document.getElementById('bigdata17kato-poster').style.display = 'block'"  onmouseout="document.getElementById('bigdata17kato-poster').style.display = 'none'">[abst]</span>   
Kasumi Kato, Atsuko Takefusa, Hidemoto Nakada, Masato Oguchi
, *IEEE BigData 2017 poster*   , pp. 4675-4677  , 2017 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="bigdata17kato-poster"> The Spread of cameras and sensors and cloud technologies enable us to obtain life logs at ordinary homes and transmit the captured data to a cloud for the life log analysis. However, the amount of processing for video data analysis in a cloud is drastically increasing when a very large number of homes send the data to the cloud. In this research, we aim to improve the efficiency of distributed video data analysis processing byusing the parallel deep learning framework Chainer and the distribution processing platform Apache Spark (Spark). Inthis paper, we focus on parallel data processing on a Spark cluster.</div> </blockquote>



- **Evaluation of Distributed Processing of Caffe Framework Using Poor Performance Device**  <span onmouseover="document.getElementById('bigdata16ichinose-poster').style.display = 'block'"  onmouseout="document.getElementById('bigdata16ichinose-poster').style.display = 'none'">[abst]</span>   
Ayae Ichinose, Atsuko Takefusa, Hidemoto Nakada, Masato Oguchi
, *IEEE Bigdata (poster)*    , 2016 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="bigdata16ichinose-poster"> The spread of various sensors and Cloud technologies has made it easy to acquire life-logs and accumulate data. As a result, many life-log analysis applications, which transfer data from sensors, especially cameras to a Cloud and analyze them in the Cloud, have been developed. However, it is difficult to transfer raw data from sensors to a Cloud because of the limitation of network bandwidth between sensors and a Cloud and privacy issues caused by sending raw sensor data. In our study, we split a deep learning processing sequence of the Caffe framework by defining new layers and performs distributed processing between a client side and a Cloud side in a pipeline manner. This approach makes it possible to protect privacy by sending not raw data but feature values, and reduce transferred data between a sensor and a Cloud. We investigate processing times of classification varying the parameters of the network models of CIFAR-10 data sets using our method.</div> </blockquote>



- **Evaluation of Distributed Processing of the Deep Learning Framework Caffe**  <span onmouseover="document.getElementById('HPDC16ichinose-poster').style.display = 'block'"  onmouseout="document.getElementById('HPDC16ichinose-poster').style.display = 'none'">[abst]</span>   
Ayae Ichinose, Atsuko Takefusa, Hidemoto Nakada, Masto Oguchi
, *The 25th International Symposium on High Performance Parallel and Distributed Computing , Poster presentation*    , 2016 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="HPDC16ichinose-poster"> Many life-log analysis applications, which transfer sensor data to a Cloud and analyze them, have been developed. We propose pipelined-based distributed deep learning processing between sensors and Clouds in order to reduce the amount of data sent to Clouds and protect the privacy of application users or the people related to the sensor data. We investigate processing times of classification and the results show that proposed distributed processing has performance advantages in the cases of insufficient network bandwidth as actual sensor and Cloud environment.</div> </blockquote>



- **Scalable and Highly Available Fault Resilient Programming Middleware for Exascale Computing**  <span onmouseover="document.getElementById('sc14poster-takefusa').style.display = 'block'"  onmouseout="document.getElementById('sc14poster-takefusa').style.display = 'none'">[abst]</span>   
Atsuko Takefusa, Tsutomu Ikegami, Hidemoto Nakada, Ryousei Takano, Takayuki Tozawa, Yoshio Tanaka
, *SC14(Poster)*    , 2014 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="sc14poster-takefusa"> Falanx is a programming middleware for the development of applications for exascale computing. Because of the fragility of the computing environment, exascale applications are required to be not only scalable, but also fault resilient. Falanx employs an MPI-based hierarchical parallel programming model for the scalability, where an application is described as a network of smaller tasks each of which are processed in a fine-grained parallel manner. 
Falanx consists of Resource Management System (RMS) and Data Store (DS): The RMS allocates processes of each task to　computing nodes avoiding nodes with failures. The DS preserves data required for each application, and prevents data loss due to failures. It is necessary that these components must be scalable and that they themselves have to be implemented in a fault resilient manner in exascale　computing environments. 
We design a scalable and highly available middleware, which consists of RMS and DS and implement them by using Apache ZooKeeper and Kyoto Cabinet. Then, we investigate the basic performance of RMS and DS from the preliminary experiments and confirm the feasibility of the middleware from an experiment using an actual application called OpenFMO.</div> </blockquote>



- **A Study of a Highly Available Distributed Self-Scheduler for Exascale Computing**  <span onmouseover="document.getElementById('hpdc14takefusa-poster').style.display = 'block'"  onmouseout="document.getElementById('hpdc14takefusa-poster').style.display = 'none'">[abst]</span>   
Atsuko Takefusa, Hidemoto Nakada, Tsutomu Ikegami, Yoshio Tanaka
, *HPDC&#x27;14 (poster)*    , 2014 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="hpdc14takefusa-poster"> We design a highly available distributed self-scheduler as a resource management system for a fault resilient application framework for exascale computing environments. The proposed distributed self-scheduler consists of multiple processes in order to realize scalability, its fault resiliency and persistency. We also develop a prototype system of the application framework, by using Apache ZooKeeper and Apache Cassandra. The experiments using the developed prototype system show that the proposed distributed self-scheduler realizes fault resiliency of an application program, developed using the framework, and the scheduler itself is also fault resilient.</div> </blockquote>



- **A Performance Study on Virtual Machine Provisioning and Backup for Storage Design of the HPC Cloud**  <span onmouseover="document.getElementById('HPDC13tanimura-poster').style.display = 'block'"  onmouseout="document.getElementById('HPDC13tanimura-poster').style.display = 'none'">[abst]</span>   
Yusuke Tanimura, Ryousei Takano, Takahiro Hamanishi, Hidemoto Nakada, Yoshio Tanaka
, *The 22nd ACM International Symposium on High-Performance Parallel and Distributed Computing (Poster)*    , 2013 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="HPDC13tanimura-poster"> Efficient virtual machine (VM) management is important for the HPC Cloud where many VMs are provisioned or backed-up by individual users who run parallel applications. In order to design a storage architecture to support such use cases, we studied I/O behavior of VM provisioning and backup, and measured performance of the existing VM provisioning methods with various hardware choices.</div> </blockquote>



- **Ninja Migration: An Interconnect-transparent Migration for Heterogeneous Data Centers**  <span onmouseover="document.getElementById('hpgcc13takano').style.display = 'block'"  onmouseout="document.getElementById('hpgcc13takano').style.display = 'none'">[abst]</span>   
Ryousei Takano, Hidemoto Nakada, Takahiro Hirofuchi, Yoshio Tanaka, Tomohiro Kudoh
, *High-Performance Grid and Cloud Computing Workshop*    , 2013 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="hpgcc13takano"> We propose an interconnect-transparent migration mechanism to simultaneously migrate multiple co-located VMs between data centers equipped with different interconnect devices. Our implementation of the proposed mechanism, called Ninja migration, is achieved by cooperation between a VMM and an MPI runtime system on the guest OS.
We demonstrate fallback and recovery operations on a high performance computing workload using the proposed mechanism. We have confirmed that 1) the proposed mechanism has no performance overhead during normal operations, and 2) MPI processes running on distributed VMs can migrate between an Infiniband cluster and an Ethernet cluster without restarting the processes.</div> </blockquote>



- **IT VIrtualization for Disaster Mitigation and Recovery**  <span onmouseover="document.getElementById('jrapidsymposium').style.display = 'block'"  onmouseout="document.getElementById('jrapidsymposium').style.display = 'none'">[abst]</span>   
Tadahiro Hirofuchi, Hidemoto Nakada, Ryousei Takano, Mauricio Tsugawa, Renato Figueiredo, Jose Fortes
, *J-RAPID Symposium*    , 2013 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="jrapidsymposium"> In today’s society, Information Technology (IT) is applied in many critical infrastructures and systems, thus it is key for IT services to quickly recover from damages caused by catastrophic events. This project conducted research on the use of virtualization technologies to architect IT infrastructures resilient to partial physical infrastructure failures. The key idea is to quickly move IT services damaged by a disaster to a safe location, taking advantage of machine and network virtualization mechanisms that allow the migration of an entire IT infrastructure from one geographical location to another. This approach has the potential to be substantially cost efficient, application independent, and offer lower downtime of services compared to traditional disaster recovery (DR) mechanisms, which requires (a) applications to be modified for a particular DR implementation and (b) expensive on-line replication of data. Given the scale in which IT services are deployed, it is prohibitively expensive to protect all of them through traditional DR services – thus, research for low cost alternatives that can be invoked on demand is needed.</div> </blockquote>



- **Stream Processing with BigData: SSS-MapReduce**  <span onmouseover="document.getElementById('cloudcom12nakada_poster').style.display = 'block'"  onmouseout="document.getElementById('cloudcom12nakada_poster').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, Hirotaka Ogawa, Tomohiro Kudoh
, *IEEE CloudCom 2012 (poster)*    , 2012 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="cloudcom12nakada_poster"> We propose a MapReduce based stream processing system, called SSS, which is capable of processing stream along with large scale static data. Unlike the existing stream processing systems that can work only on the relatively small on-memory data-set, SSS can process incoming streamed data consulting the stored data. SSS processes streamed data with continuous Mappers and Reducers, that are periodically invoked by the system. It also supports merge operation on two set of data, which enables stream data processing with large static data.</div> </blockquote>



- **Stream Processing with Bigdata by SSS-MapReduce** [[Paper](dataDir/eScience12nakada_poster.pdf)]  <span onmouseover="document.getElementById('eScience12nakada_poster').style.display = 'block'"  onmouseout="document.getElementById('eScience12nakada_poster').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, Hirotaka Ogawa, Tomohiro Kudoh
, *IEEE International Conference on eScience (eScience 2012) (poster)*    , 2012 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="eScience12nakada_poster"> We propose a MapReduce based stream processing system, called SSS, which is capable of processing stream along with large scale static data. Unlike the existing stream processing systems that can work only on the relatively small on-memory data-set, SSS can process incoming streamed data consulting the stored data. SSS processes streamed data with continuous Mappers and Reducers, that are periodically invoked by the system. It also supports merge operation on two set of data, which enables stream data processing with large static data.</div> </blockquote>



- **An Implementation of Sawzall on Hadoop** [[Paper](dataDir/cute11nakada.pdf)] [[Slides](dataDir/cute11nakada-slides.pdf)]  <span onmouseover="document.getElementById('cute11nakada').style.display = 'block'"  onmouseout="document.getElementById('cute11nakada').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, Tatsuhiko Inoue, Tomohiro Kudoh
, *CUTE 2011(The 6th International Conference on Ubiquitous Information Technologies &amp; Applications)*    , 2011 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="cute11nakada"> Sawzall is a script language designed for batch processing of large amount of data, based on MapReduce parallel execution model, which is introduced by Google in 2006. Sawzall allows programmers only to program {\it mappers} to ease the burden for them. Sawzall provides a set of built-in {\it aggregators} that provides reducing function, from which programmers could pick and use. We have implemented a Sawzall compiler and runtime, called \scns, which allows Sawzall scripts to run in parallel on Hadoop. We employed Scala language to leverage Scala&#x27;s parser combinator libraries for Sawzall syntax parsing. It enabled easy implementation of parser and potential future extension of the language. This paper provides detailed implementation of the system. We performed evaluation on the system comparing with the Java programs that use native Hadoop API and szl, a Sawzall open source implementation from Google. We confirmed that overhead imposed by \sc is small enough, and the execution speed is comparable with szl.</div> </blockquote>



- **Implementation and evaluation of SSS: a Key-Value Store based MapReduce Framework**  <span onmouseover="document.getElementById('cloudcom11poster-nakada').style.display = 'block'"  onmouseout="document.getElementById('cloudcom11poster-nakada').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, Hirotaka Ogawa, Tomohiro Kudoh
, *CloudCom 2011 poster*    , 2011 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="cloudcom11poster-nakada"> Design and Implementation of a MapReduce framework SSS are described. MapReduce is considered to be a promising parallel programming model for broad range of applications. For that purpose, a flexible MapReduce framework is required that enables programmers to easily combine Mappers and Reducers into workflows that may involve iterations. Hadoop, the most widely used MapReduce framework, is not flexible enough, however. Iteration overhead of Hadoop is too big to perform fine-grained iterations. A job in Hadoop always composed of one Mapper and one Reducer, limiting the shape of workflows. We propose a MapReduce framework based on distributed KVS, called SSS. In SSS, Mappers and Reducers have the same data access pattern. making possible to have flexible combination of Mappers and Reducers. Furthermore, SSS employs Owner Computes Rule which enables faster iteration. Here, we provide detailed design and implementation of SSS. We also demonstrate the performance of SSS using K-means clustering application.</div> </blockquote>



- **GridARS Resource Management Framework for InterCloud**  <span onmouseover="document.getElementById('sc11poster-takefusa').style.display = 'block'"  onmouseout="document.getElementById('sc11poster-takefusa').style.display = 'none'">[abst]</span>   
Atsuko Takefusa, Hidemoto Nakada, Ryousei Takano, Tomohiro Kudoh, Yoshio Tanaka
, *SC11 Poster*    , 2011 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="sc11poster-takefusa"> Cloud computing is considered as an attractive infrastructure for data intensive applications. However, current cloud services do not support construction of a virtual infrastructure over distributed InterCloud resources. Furthermore, the performance of the infrastructure, including storage and network resources, is not assured. We are developing a resource management framework called GridARS (Grid Advance Reservation-based System framework) that integrates not only computers and storage, but also networks, constructing a QoS-guaranteed virtual infrastructure over these resources. GridARS is a reference implementation of GNS-WSI (Grid Network Service - Web Services Interface), defined by the G-lambda project. GridARS provides a wrapper software for existing resource management systems and it enables construction of a virtual infrastructure, based on advance reservation, and also provides monitoring information, dynamically. In this poster, we present overview, the performance and extension of GridARS, introduction of GLIF2010 and SC10 demonstration, and interoperation to NSI, defined by OGF.</div> </blockquote>



- **SSS：a MapReduce Framework based on Distributed Key-value Store** [[Paper](dataDir/sc11poster-nakada.pdf)]  <span onmouseover="document.getElementById('sc11poster-nakada').style.display = 'block'"  onmouseout="document.getElementById('sc11poster-nakada').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, Hirotaka Ogawa, Tomohiro Kudoh
, *SC11 Poster*    , 2011 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="sc11poster-nakada"> MapReduce has been very successful in implementing large-scale data-intensive applications. Because of its simple programming model, MapReduce has also begun being utilized as a programming tool for more general distributed and parallel HPC applications. However, its applicability is often limited due to relatively inefficient runtime performance and hence insufficient support for flexible workflows. In particular, the performance problem is not negligible in iterative MapReduce applications. We implemented new MapReduce framework SSS based on distributed key-value store, that supports flexible workflows. Mappers and reducers read key-values only from its local storage enjoying high throughput and low latency. We evaluated SSS comparing with Hadoop using synthetic benchmark and real application. The result showed that SSS is significantly faster than Hadoop, especially for shuffle-intensive jobs and iterative jobs.</div> </blockquote>



- **Enabling Greener Cloud Datacenters with Advanced Virtualization Technology**    
Takahiro Hirofuchi, Hidemoto Nakada, Satoshi Itoh, Satoshi Sekiguchi
, *The 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid2010) (Poster)*    , 2010 



- **Network as a resource: G-lambda project and its architecture**    
Tomohiro Kudoh, Michiaki Hayashi, Akira Hirano, Shuichi Okamoto, Atsuko Takefusa, Takahiro Miyamoto, Yukio Tsukishima, Tomohiro Otani, Hidemoto Nakada, Hideaki Tanaka, Atsushi Taniguchi, Yasunori Sameshima, Masahiko Jinno
, *First International Conference on Networks for Grid Applications*    , 2007 



- **GNS-WSI2 Grid Network Service - Web Services Interface, version 2**    
Atsuko Takefusa, Michiaki Hayashi, Akira Hirano, Shuichi Okamoto, Tomohiro Kudoh, Takahiro Miyamoto, Yukio Tsukishima, Tomohiro Otani, Hidemoto Nakada, Hideaki Tanaka, Atsushi Taniguchi, Yasunori Sameshima
, *OGF19 GHPN-RG*    , 2007 



- **GridRPC Tutorial**    
Hidemoto Nakada, Satoshi Matsuoka, Mitsuhisa Sato, Satoshi Sekiguchi 
, *CCGrid  2003*    , 2003 



- **A Java-based Programming Environment for the Grid: Jojo**  <span onmouseover="document.getElementById('ccgrid03posterNakada').style.display = 'block'"  onmouseout="document.getElementById('ccgrid03posterNakada').style.display = 'none'">[abst]</span>   
Hidemoto Nakada, Satoshi Matsuoka, Satoshi Sekiguchi
, *CCGrid 2003 Poster*    , 2003 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="ccgrid03posterNakada"> This poster introduces a java-based programming environment for the Grid, called Jojo. Jojo is a distributed programming environment implemented in Java. It is suitable for a grid environment consists of cluster of clusters. Jojo provides several features, including secure remote invocation using Globus GRAM, intuitive message passing API suitable for parallel execution and automatic user program staging. Jojo helps users to construct their own parallel-distributed application on the Grid. In the poster, we show design and implementation of Jojo, its programming API and a working program example. We also show preliminary performance evaluation result.</div> </blockquote>



- **Ninf Project**    
Kento Aida, Atsuko Takefusa, Hirotaka Ogawa, Osamu Tatebe, Hidemoto Nakada, Hiromitsu Takagi, Yoshio Tanaka, Satoshi Matsuoka, Mitsuhisa Sato, Satoshi Sekiguchi, Umpei Nagashima
, *APAN Conference 2000*    , 2000 



- **A Performance Evaluation Model for Scheduling in Global Computing Systems**    
Kento Aida, Atsuko Takefusa, Hidemoto Nakada, Satoshi Matsuoka, Satoshi Sekiguchi, Umpei Nagashima
, *NASA Workshop on Performance-Engineered Information Systems*    , 1998 



- **Ninf Global Computing System - Architecture, Features, and Performance**    
Hidemoto Nakada, Atsuko Takefusa, Hirotaka Ogawa, Kento Aida, Hiromitsu Takagi, Satoshi Matsuoka, Umpei Nagashima, Mitsuhisa Sato, Satoshi Sekiguchi
, *HPCN Workshop on Distributed Computing (Oral presentation)*    , 1998 



- **Preliminary Evaluation of Scheduling in Ninf: a Global Computing System**  <span onmouseover="document.getElementById('iwia97matsuoka').style.display = 'block'"  onmouseout="document.getElementById('iwia97matsuoka').style.display = 'none'">[abst]</span>   
Satoshi Matsuoka, Hirotaka Ogawa, Atsuko Takefusa, Hidemoto Nakada, Kento Aida, Umpei Nagashima, Mitsuhisa Sato, Satoshi Sekiguchi
, *International Workshop on Innovative Architectures &#x27;97*   , pp. 7p  , 1997 

> <blockquote> <div style="text-align: justify; display: none; background: lightgrey; margin: 0 0 0 30pt" id="iwia97matsuoka"> Rapid increase in speed and availability of global-network is opening up the possibilities of globally-distributed supercomputing, including our Ninf system. However, performance characteristics of these systems have been little investigated, especially under multi-clients, multi-sites situations. In order to establish methodology to schedule multiple job requests to multiple computational servers effectively and guarantee performance per each client, we conducted benchmarks under various WAN environments. There, we observed that communication bandwidth dominated performance for communication-intensive applications such as Linpack, and aggregate bandwidth could be sustained for multi-clients located at different internet sites. Based on these observations, we propose the need for a simulation model based on queuing theory. And we also performed preliminary benchmarks using our scheduling server, called the Ninf Metaserver. We also report on our collaborative efforts in bridging Ninf with NetSolve, a similar system being developed at Univ. of Tennessee/ORNL.</div> </blockquote>



- **Fleng on PIE64 and Its Programming Environment**    
Hidemoto Nakada, Hanpei Koike, Hidehiko Tanaka
, *PARALLEL LANGUAGE AND COMPILER RESERCH IN JAPAN*    , 1994 



        
